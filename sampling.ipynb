{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.combine import SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 772 entries, 0 to 771\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Time    772 non-null    int64  \n",
      " 1   V1      772 non-null    float64\n",
      " 2   V2      772 non-null    float64\n",
      " 3   V3      772 non-null    float64\n",
      " 4   V4      772 non-null    float64\n",
      " 5   V5      772 non-null    float64\n",
      " 6   V6      772 non-null    float64\n",
      " 7   V7      772 non-null    float64\n",
      " 8   V8      772 non-null    float64\n",
      " 9   V9      772 non-null    float64\n",
      " 10  V10     772 non-null    float64\n",
      " 11  V11     772 non-null    float64\n",
      " 12  V12     772 non-null    float64\n",
      " 13  V13     772 non-null    float64\n",
      " 14  V14     772 non-null    float64\n",
      " 15  V15     772 non-null    float64\n",
      " 16  V16     772 non-null    float64\n",
      " 17  V17     772 non-null    float64\n",
      " 18  V18     772 non-null    float64\n",
      " 19  V19     772 non-null    float64\n",
      " 20  V20     772 non-null    float64\n",
      " 21  V21     772 non-null    float64\n",
      " 22  V22     772 non-null    float64\n",
      " 23  V23     772 non-null    float64\n",
      " 24  V24     772 non-null    float64\n",
      " 25  V25     772 non-null    float64\n",
      " 26  V26     772 non-null    float64\n",
      " 27  V27     772 non-null    float64\n",
      " 28  V28     772 non-null    float64\n",
      " 29  Amount  772 non-null    float64\n",
      " 30  Class   772 non-null    int64  \n",
      "dtypes: float64(29), int64(2)\n",
      "memory usage: 187.1 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "url = \"https://github.com/AnjulaMehto/Sampling_Assignment/raw/main/Creditcard_data.csv\"\n",
    "df = pd.read_csv(url)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "0    763\n",
      "1    763\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "ros = RandomOverSampler(sampling_strategy='auto', random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "df_balanced = pd.concat([pd.DataFrame(X_resampled, columns=X.columns), pd.Series(y_resampled, name='Class')], axis=1)\n",
    "print(df_balanced['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = min(df_balanced['Class'].value_counts())\n",
    "samples = [df_balanced.groupby('Class', group_keys=False).apply(lambda x: x.sample(min(len(x), sample_size))) for _ in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 1 - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       143\n",
      "           1       1.00      1.00      1.00       163\n",
      "\n",
      "    accuracy                           1.00       306\n",
      "   macro avg       1.00      1.00      1.00       306\n",
      "weighted avg       1.00      1.00      1.00       306\n",
      "\n",
      "\n",
      "Sample 2 - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       143\n",
      "           1       1.00      1.00      1.00       163\n",
      "\n",
      "    accuracy                           1.00       306\n",
      "   macro avg       1.00      1.00      1.00       306\n",
      "weighted avg       1.00      1.00      1.00       306\n",
      "\n",
      "\n",
      "Sample 3 - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       143\n",
      "           1       1.00      1.00      1.00       163\n",
      "\n",
      "    accuracy                           1.00       306\n",
      "   macro avg       1.00      1.00      1.00       306\n",
      "weighted avg       1.00      1.00      1.00       306\n",
      "\n",
      "\n",
      "Sample 4 - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       143\n",
      "           1       1.00      1.00      1.00       163\n",
      "\n",
      "    accuracy                           1.00       306\n",
      "   macro avg       1.00      1.00      1.00       306\n",
      "weighted avg       1.00      1.00      1.00       306\n",
      "\n",
      "\n",
      "Sample 5 - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       143\n",
      "           1       1.00      1.00      1.00       163\n",
      "\n",
      "    accuracy                           1.00       306\n",
      "   macro avg       1.00      1.00      1.00       306\n",
      "weighted avg       1.00      1.00      1.00       306\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, sample in enumerate(samples):\n",
    "    X_sample = sample.drop('Class', axis=1)\n",
    "    y_sample = sample['Class']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=0.2, random_state=42)\n",
    "    model = RandomForestClassifier(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print(f\"\\nSample {i+1} - Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 1 - Classification Report for M2 with RandomUnderSampler:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       143\n",
      "           1       0.99      1.00      1.00       163\n",
      "\n",
      "    accuracy                           1.00       306\n",
      "   macro avg       1.00      1.00      1.00       306\n",
      "weighted avg       1.00      1.00      1.00       306\n",
      "\n",
      "\n",
      "Sample 2 - Classification Report for M2 with RandomUnderSampler:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       143\n",
      "           1       0.99      1.00      1.00       163\n",
      "\n",
      "    accuracy                           1.00       306\n",
      "   macro avg       1.00      1.00      1.00       306\n",
      "weighted avg       1.00      1.00      1.00       306\n",
      "\n",
      "\n",
      "Sample 3 - Classification Report for M2 with RandomUnderSampler:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       143\n",
      "           1       0.98      1.00      0.99       163\n",
      "\n",
      "    accuracy                           0.99       306\n",
      "   macro avg       0.99      0.99      0.99       306\n",
      "weighted avg       0.99      0.99      0.99       306\n",
      "\n",
      "\n",
      "Sample 4 - Classification Report for M2 with RandomUnderSampler:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       143\n",
      "           1       0.99      1.00      1.00       163\n",
      "\n",
      "    accuracy                           1.00       306\n",
      "   macro avg       1.00      1.00      1.00       306\n",
      "weighted avg       1.00      1.00      1.00       306\n",
      "\n",
      "\n",
      "Sample 5 - Classification Report for M2 with RandomUnderSampler:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       143\n",
      "           1       0.99      1.00      0.99       163\n",
      "\n",
      "    accuracy                           0.99       306\n",
      "   macro avg       0.99      0.99      0.99       306\n",
      "weighted avg       0.99      0.99      0.99       306\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, sample in enumerate(samples):\n",
    "    X_sample = sample.drop('Class', axis=1)\n",
    "    y_sample = sample['Class']\n",
    "    rus = RandomUnderSampler(sampling_strategy='auto', random_state=42)\n",
    "    X_resampled, y_resampled = rus.fit_resample(X_sample, y_sample)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "    model = GradientBoostingClassifier(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print(f\"\\nSample {i+1} - Classification Report for M2 with RandomUnderSampler:\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 1 - Classification Report for M2 with SMOTE:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       143\n",
      "           1       0.99      1.00      1.00       163\n",
      "\n",
      "    accuracy                           1.00       306\n",
      "   macro avg       1.00      1.00      1.00       306\n",
      "weighted avg       1.00      1.00      1.00       306\n",
      "\n",
      "\n",
      "Sample 2 - Classification Report for M2 with SMOTE:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       143\n",
      "           1       0.99      1.00      1.00       163\n",
      "\n",
      "    accuracy                           1.00       306\n",
      "   macro avg       1.00      1.00      1.00       306\n",
      "weighted avg       1.00      1.00      1.00       306\n",
      "\n",
      "\n",
      "Sample 3 - Classification Report for M2 with SMOTE:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       143\n",
      "           1       0.98      1.00      0.99       163\n",
      "\n",
      "    accuracy                           0.99       306\n",
      "   macro avg       0.99      0.99      0.99       306\n",
      "weighted avg       0.99      0.99      0.99       306\n",
      "\n",
      "\n",
      "Sample 4 - Classification Report for M2 with SMOTE:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       143\n",
      "           1       0.99      1.00      1.00       163\n",
      "\n",
      "    accuracy                           1.00       306\n",
      "   macro avg       1.00      1.00      1.00       306\n",
      "weighted avg       1.00      1.00      1.00       306\n",
      "\n",
      "\n",
      "Sample 5 - Classification Report for M2 with SMOTE:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       143\n",
      "           1       0.99      1.00      0.99       163\n",
      "\n",
      "    accuracy                           0.99       306\n",
      "   macro avg       0.99      0.99      0.99       306\n",
      "weighted avg       0.99      0.99      0.99       306\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, sample in enumerate(samples):\n",
    "    X_sample = np.array(sample.drop('Class', axis=1))\n",
    "    y_sample = np.array(sample['Class'])\n",
    "\n",
    "    smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X_sample, y_sample)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "    model = GradientBoostingClassifier(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print(f\"\\nSample {i+1} - Classification Report for M2 with SMOTE:\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 1 - Classification Report for M3 with NearMiss:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.73      0.71       143\n",
      "           1       0.75      0.73      0.74       163\n",
      "\n",
      "    accuracy                           0.73       306\n",
      "   macro avg       0.73      0.73      0.73       306\n",
      "weighted avg       0.73      0.73      0.73       306\n",
      "\n",
      "\n",
      "Sample 2 - Classification Report for M3 with NearMiss:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.66      0.65       143\n",
      "           1       0.69      0.66      0.67       163\n",
      "\n",
      "    accuracy                           0.66       306\n",
      "   macro avg       0.66      0.66      0.66       306\n",
      "weighted avg       0.66      0.66      0.66       306\n",
      "\n",
      "\n",
      "Sample 3 - Classification Report for M3 with NearMiss:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.72      0.71       143\n",
      "           1       0.75      0.73      0.74       163\n",
      "\n",
      "    accuracy                           0.73       306\n",
      "   macro avg       0.72      0.73      0.72       306\n",
      "weighted avg       0.73      0.73      0.73       306\n",
      "\n",
      "\n",
      "Sample 4 - Classification Report for M3 with NearMiss:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.77      0.71       143\n",
      "           1       0.76      0.66      0.71       163\n",
      "\n",
      "    accuracy                           0.71       306\n",
      "   macro avg       0.71      0.71      0.71       306\n",
      "weighted avg       0.72      0.71      0.71       306\n",
      "\n",
      "\n",
      "Sample 5 - Classification Report for M3 with NearMiss:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.76      0.70       143\n",
      "           1       0.75      0.66      0.70       163\n",
      "\n",
      "    accuracy                           0.70       306\n",
      "   macro avg       0.71      0.71      0.70       306\n",
      "weighted avg       0.71      0.70      0.70       306\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, sample in enumerate(samples):\n",
    "    X_sample = sample.drop('Class', axis=1)\n",
    "    y_sample = sample['Class']\n",
    "    nm = NearMiss(sampling_strategy='auto', version=1)\n",
    "    X_resampled, y_resampled = nm.fit_resample(X_sample, y_sample)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "    model = SVC(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print(f\"\\nSample {i+1} - Classification Report for M3 with NearMiss:\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 1 - Classification Report for M4 with ADASYN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98       143\n",
      "           1       0.97      1.00      0.98       163\n",
      "\n",
      "    accuracy                           0.98       306\n",
      "   macro avg       0.99      0.98      0.98       306\n",
      "weighted avg       0.98      0.98      0.98       306\n",
      "\n",
      "\n",
      "Sample 2 - Classification Report for M4 with ADASYN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99       143\n",
      "           1       0.98      1.00      0.99       163\n",
      "\n",
      "    accuracy                           0.99       306\n",
      "   macro avg       0.99      0.99      0.99       306\n",
      "weighted avg       0.99      0.99      0.99       306\n",
      "\n",
      "\n",
      "Sample 3 - Classification Report for M4 with ADASYN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98       143\n",
      "           1       0.96      1.00      0.98       163\n",
      "\n",
      "    accuracy                           0.98       306\n",
      "   macro avg       0.98      0.98      0.98       306\n",
      "weighted avg       0.98      0.98      0.98       306\n",
      "\n",
      "\n",
      "Sample 4 - Classification Report for M4 with ADASYN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       143\n",
      "           1       0.98      1.00      0.99       163\n",
      "\n",
      "    accuracy                           0.99       306\n",
      "   macro avg       0.99      0.99      0.99       306\n",
      "weighted avg       0.99      0.99      0.99       306\n",
      "\n",
      "\n",
      "Sample 5 - Classification Report for M4 with ADASYN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99       143\n",
      "           1       0.98      1.00      0.99       163\n",
      "\n",
      "    accuracy                           0.99       306\n",
      "   macro avg       0.99      0.99      0.99       306\n",
      "weighted avg       0.99      0.99      0.99       306\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, sample in enumerate(samples):\n",
    "    X_sample = sample.drop('Class', axis=1)\n",
    "    y_sample = sample['Class']\n",
    "\n",
    "    adasyn = ADASYN(sampling_strategy='auto', random_state=42)\n",
    "    X_resampled, y_resampled = adasyn.fit_resample(X_sample, y_sample)\n",
    "    X_resampled = np.array(X_resampled)\n",
    "    y_resampled = np.array(y_resampled)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "    X_train = np.ascontiguousarray(X_train)\n",
    "    X_test = np.ascontiguousarray(X_test)\n",
    "\n",
    "    model = KNeighborsClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"\\nSample {i+1} - Classification Report for M4 with ADASYN:\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: M1, Sampling Technique: RandomOverSampler, Accuracy: 0.9967\n",
      "\n",
      "Model: M1, Sampling Technique: SMOTE, Accuracy: 0.9967\n",
      "\n",
      "Model: M1, Sampling Technique: NearMiss, Accuracy: 0.9902\n",
      "\n",
      "Model: M1, Sampling Technique: ADASYN, Accuracy: 0.9967\n",
      "\n",
      "Model: M1, Sampling Technique: SMOTEENN, Accuracy: 0.9967\n",
      "\n",
      "Model: M2, Sampling Technique: RandomOverSampler, Accuracy: 0.7059\n",
      "\n",
      "Model: M2, Sampling Technique: SMOTE, Accuracy: 0.6536\n",
      "\n",
      "Model: M2, Sampling Technique: NearMiss, Accuracy: 0.7255\n",
      "\n",
      "Model: M2, Sampling Technique: ADASYN, Accuracy: 0.7386\n",
      "\n",
      "Model: M2, Sampling Technique: SMOTEENN, Accuracy: 0.7815\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Flags' object has no attribute 'c_contiguous'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X_resampled, y_resampled, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     29\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m---> 30\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_names[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Sampling Technique: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msampling_techniques[j]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/sklearn-env/lib/python3.11/site-packages/sklearn/neighbors/_classification.py:246\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    244\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_fit_method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 246\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrute\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mArgKminClassMode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_usable_for\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetric\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    249\u001b[0m         probabilities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_proba(X)\n\u001b[1;32m    250\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs_2d_:\n",
      "File \u001b[0;32m~/anaconda3/envs/sklearn-env/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:471\u001b[0m, in \u001b[0;36mArgKminClassMode.is_usable_for\u001b[0;34m(cls, X, Y, metric)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_usable_for\u001b[39m(\u001b[38;5;28mcls\u001b[39m, X, Y, metric) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m    450\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return True if the dispatcher can be used for the given parameters.\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \n\u001b[1;32m    452\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;124;03m    True if the PairwiseDistancesReduction can be used, else False.\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 471\u001b[0m         \u001b[43mArgKmin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_usable_for\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    472\u001b[0m         \u001b[38;5;66;03m# TODO: Support CSR matrices.\u001b[39;00m\n\u001b[1;32m    473\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m issparse(X)\n\u001b[1;32m    474\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m issparse(Y)\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;66;03m# TODO: implement Euclidean specialization with GEMM.\u001b[39;00m\n\u001b[1;32m    476\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m metric \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meuclidean\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqeuclidean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    477\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/sklearn-env/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:115\u001b[0m, in \u001b[0;36mBaseDistancesReductionDispatcher.is_usable_for\u001b[0;34m(cls, X, Y, metric)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_valid_sparse_matrix\u001b[39m(X):\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    103\u001b[0m         isspmatrix_csr(X)\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    110\u001b[0m         X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mint32\n\u001b[1;32m    111\u001b[0m     )\n\u001b[1;32m    113\u001b[0m is_usable \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    114\u001b[0m     get_config()\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menable_cython_pairwise_dist\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[43mis_numpy_c_ordered\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m is_valid_sparse_matrix(X))\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (is_numpy_c_ordered(Y) \u001b[38;5;129;01mor\u001b[39;00m is_valid_sparse_matrix(Y))\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m Y\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01min\u001b[39;00m (np\u001b[38;5;241m.\u001b[39mfloat32, np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mvalid_metrics()\n\u001b[1;32m    120\u001b[0m )\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_usable\n",
      "File \u001b[0;32m~/anaconda3/envs/sklearn-env/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:99\u001b[0m, in \u001b[0;36mBaseDistancesReductionDispatcher.is_usable_for.<locals>.is_numpy_c_ordered\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_numpy_c_ordered\u001b[39m(X):\n\u001b[0;32m---> 99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflags\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflags\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_contiguous\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Flags' object has no attribute 'c_contiguous'"
     ]
    }
   ],
   "source": [
    "models = [GradientBoostingClassifier(random_state=42),\n",
    "          SVC(random_state=42),\n",
    "          KNeighborsClassifier(),\n",
    "          RandomForestClassifier(random_state=42),\n",
    "          RandomForestClassifier(random_state=42)] \n",
    "\n",
    "model_names = ['M1', 'M2', 'M3', 'M4', 'M5']\n",
    "sampling_techniques = ['RandomOverSampler', 'SMOTE', 'NearMiss', 'ADASYN', 'SMOTEENN']\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    for j, sample in enumerate(samples):\n",
    "        X_sample = sample.drop('Class', axis=1)\n",
    "        y_sample = sample['Class']\n",
    "\n",
    "        if sampling_techniques[j] == 'RandomOverSampler':\n",
    "            sampler = RandomOverSampler(sampling_strategy='auto', random_state=42)\n",
    "        elif sampling_techniques[j] == 'SMOTE':\n",
    "            sampler = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "        elif sampling_techniques[j] == 'NearMiss':\n",
    "            sampler = NearMiss(sampling_strategy='auto', version=1)\n",
    "        elif sampling_techniques[j] == 'ADASYN':\n",
    "            sampler = ADASYN(sampling_strategy='auto', random_state=42)\n",
    "        elif sampling_techniques[j] == 'SMOTEENN':\n",
    "            sampler = SMOTEENN(sampling_strategy='auto', random_state=42)\n",
    "\n",
    "        X_resampled, y_resampled = sampler.fit_resample(X_sample, y_sample)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"\\nModel: {model_names[i]}, Sampling Technique: {sampling_techniques[j]}, Accuracy: {accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
